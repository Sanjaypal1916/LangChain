{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4fae57e-5d27-41b1-b086-b38603bc301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fccbfe1-c4f5-492f-9228-2402a9bd9c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (5.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf\n",
    "loader = PyPDFLoader(\"./census/acsbr-015.pdf\")\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f63a67c-3704-4abc-85cd-2f8c8733b2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sanjay\\desktop\\ai ml\\dev\\langchain\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defd844993e643ad9ac46dd0b6147ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanjay\\Desktop\\AI ML\\DEV\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sanjay\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7478e7ebfd443cb97fe7137753719c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a7ee0b7ddb40ce8d26bd61521378a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58af21c45e154a1286164eabdf77a2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa314ad87be483890aec8edb4248792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bec9e00e9d419f9c81e1e0472e896e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a72a4c0f844d77bfba77cd5511fa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55790b9ad7984ca5a816026bf3eb24ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed15523de124e6a81f77ce0a19b9568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c08419caae4cf3af05f52f445dba47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849c671a1f1d4caab29fa9f617c861ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "\n",
    "text_split = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "document = text_split.split_documents(doc)\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",      #sentence-transformers/all-MiniLM-l6-v2\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True}\n",
    ")\n",
    "vector = FAISS.from_documents(doc[:50], embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "311d2d60-1526-48a3-a6ea-199c59931e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f1404aa-8b6f-4024-8791-fd60d6ee2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d6f643b-665e-43d8-a026-3300e2408274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    task=\"text-generation\",\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    temperature=0.7,\n",
    "    model_kwargs={\n",
    "        \"max_length\":500\n",
    "    },\n",
    "    huggingfacehub_api_token=\"XXXX\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86459328-4dc5-4518-ae41-96b0e0ad0e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanjay\\Desktop\\AI ML\\DEV\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" in 2021-2022?\\n\\nAs of 2021, the President of India is Ram Nath Kovind. He was elected on July 19, 2017, and his term ends on July 24, 2022. However, the President of India for the year 2022-2023 will be elected in the summer of 2022. The President is the head of state in India, while the Prime Minister is the head of government. The President's role is largely ceremonial, but they do have some important powers, such as the power to veto certain bills passed by Parliament.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"who is the president of india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7ccb186-e9c2-4aac-8970-0bb03b9e93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following piece of context to answer the question asked.\n",
    "Please try to provide the answer only based on the context\n",
    "\n",
    "{context}\n",
    "Question:{question}\n",
    "\n",
    "Helpful Answers:\n",
    " \"\"\"\n",
    "prompt=PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f3b9232-9483-40c6-812a-2da6eb0979bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = RetrievalQA.from_chain_type(\n",
    "    llm = llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c27a2e14-bef4-40c5-a756-b48336883678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanjay\\Desktop\\AI ML\\DEV\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Seven states had a decrease in uninsured rate in 2022 that was driven by increases in private coverage. These states were Florida, Kansas, Mississippi, North Carolina, Ohio, South Carolina, and Texas.\n",
      "\n",
      "2. For seven states, the uninsured rate decrease was related to increases in public coverage with no corresponding change in the level of private coverage. These states were Alabama, California, Georgia, Illinois, Indiana, Michigan, and Oklahoma.\n",
      "\n",
      "3. In three states (Missouri, New York, and Virginia), it was shifts in coverage from private to public that contributed to the decline in their uninsured rates.\n",
      "\n",
      "4. Massachusetts had the lowest uninsured rate and Texas had the highest in 2022.\n",
      "\n",
      "5. In 2022, Utah had the highest private coverage and lowest public coverage rate, while New Mexico had the highest public coverage and lowest private coverage rate.\n",
      "\n",
      "6. Across the 25 most populous metropolitan areas, Boston-Cambridge-Newton, MA-NH had the lowest uninsured rate in 2022, while three metropolitan areas in Texas had the highest uninsured rates, consistent with the stateâ€™s uninsured state ranking.\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"DIFFERENCES IN THE\n",
    "UNINSURED RATE BY STATE\n",
    "IN 2022\"\"\"\n",
    "# Call the QA chain with our query.\n",
    "result = retrieval.invoke({\"query\": query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc184246-479e-43fb-b2f1-26099f05d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prmpt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"input\"],\n",
    "    template=\"\"\"\n",
    "    Use the following context to answer the input question.\n",
    "    Context: {context}\n",
    "    Question: {input}\n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2697bec-fdf4-4a36-81de-2a8e8ccc22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, prmpt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "170fc2e1-df29-433d-b5a3-3856776d8bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanjay\\Desktop\\AI ML\\DEV\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In 2022, the uninsured rate in Texas was 16.6%.\n"
     ]
    }
   ],
   "source": [
    "result = retrieval_chain.invoke({\"input\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62348495-923e-490c-a9e3-f6c1bf6e9cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9a86d-eb7b-4c4c-b1a6-1e254a4eb3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a6f1d-879c-4e4d-8011-a4859d82e646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
